{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üá´üáÆ Finnish TTS Training - Brev Launchables\n",
    "\n",
    "**Production-ready training notebook for Fish Speech + LoRA fine-tuning**\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "```bash\n",
    "# 1. SSH into Brev instance\n",
    "ssh user@instance-ip\n",
    "\n",
    "# 2. Authenticate with HuggingFace\n",
    "huggingface-cli login  # Paste your token\n",
    "\n",
    "# 3. Run setup (if not already done)\n",
    "cd ~/nvidia-brev-launchables\n",
    "bash setup.sh\n",
    "\n",
    "# 4. Start training\n",
    "jupyter notebook finnish-tts-launchables.ipynb\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Pre-flight Checks\n",
    "\n",
    "Verify all prerequisites before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PRE-FLIGHT CHECKS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check setup.sh was run\n",
    "setup_state_file = Path.home() / '.finnish-tts-setup-state'\n",
    "if setup_state_file.exists():\n",
    "    with open(setup_state_file) as f:\n",
    "        steps = f.read().strip().split('\\n')\n",
    "    print(f\"\\n‚úÖ Setup completed ({len(steps)} steps)\")\n",
    "    for step in steps:\n",
    "        print(f\"   ‚úì {step}\")\nelse:\n",
    "    print(\"\\n‚ö†Ô∏è  setup.sh may not have been run completely\")\n",
    "    print(\"   Run: bash setup.sh\")\n",
    "\n",
    "# Check HF authentication\nprint(\"\\n‚úì Checking HuggingFace authentication...\")\nhf_cache = Path.home() / '.cache' / 'huggingface' / 'token'\nif hf_cache.exists():\n",
    "    print(\"  ‚úÖ HuggingFace token found\")\n",
    "else:\n",
    "    print(\"  ‚ö†Ô∏è  HuggingFace token not found\")\n",
    "    print(\"     Run: huggingface-cli login\")\n",
    "\n",
    "# Check GPU\nprint(\"\\n‚úì Checking GPU...\")\nimport torch\nif torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "    print(f\"  ‚úÖ GPU: {gpu_name} ({gpu_mem:.1f}GB)\")\n",
    "else:\n",
    "    print(\"  ‚ùå No GPU detected! Aborting.\")\n",
    "    raise RuntimeError(\"GPU required for training\")\n",
    "\n",
    "# Check Fish Speech\nfish_dir = Path.home() / 'fish-speech'\nif fish_dir.exists():\n",
    "    print(f\"  ‚úÖ Fish Speech: {fish_dir}\")\n",
    "else:\n",
    "    print(f\"  ‚ö†Ô∏è  Fish Speech not found at {fish_dir}\")\n",
    "\nprint(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Pre-flight checks passed!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "\n",
    "Configure paths and imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import subprocess\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "from datetime import datetime\n",
    "import glob\n",
    "\n",
    "# Paths\n",
    "HOME = Path.home()\n",
    "REPO_DIR = HOME / 'nvidia-brev-launchables'\n",
    "FISH_SPEECH_DIR = HOME / 'fish-speech'\n",
    "WORK_DIR = HOME / 'finnish-tts-training'  # fallback work directory\n",
    "\n",
    "# Ensure work directory exists\n",
    "WORK_DIR.mkdir(exist_ok=True, parents=True)\n",
    "os.chdir(WORK_DIR)\n",
    "\n",
    "# Add Fish Speech to path\n",
    "sys.path.insert(0, str(FISH_SPEECH_DIR))\n",
    "\n",
    "print(f\"Repository: {REPO_DIR}\")\n",
    "print(f\"Fish Speech: {FISH_SPEECH_DIR}\")\n",
    "print(f\"Work Dir: {WORK_DIR}\")\n",
    "print(f\"\\n‚úÖ Paths configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: GPU Auto-Configuration\n",
    "\n",
    "Detect GPU and set optimal training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"GPU AUTO-CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "gpu_name = torch.cuda.get_device_name(0)\n",
    "gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "\n",
    "print(f\"\\n‚úÖ GPU: {gpu_name}\")\n",
    "print(f\"‚úÖ VRAM: {gpu_memory:.1f} GB\")\n",
    "print(f\"‚úÖ CUDA: {torch.version.cuda}\")\n",
    "print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "\n",
    "# Auto-configure\n",
    "if 'L40S' in gpu_name:\n",
    "    BATCH_SIZE = 4\n",
    "    NUM_WORKERS = 6\n",
    "    ACCUMULATE_GRAD = 1\n",
    "    GPU_CONFIG = \"L40S (48GB)\"\nelif 'A100' in gpu_name:\n",
    "    if gpu_memory > 70:\n",
    "        BATCH_SIZE = 8\n",
    "        NUM_WORKERS = 8\n",
    "        ACCUMULATE_GRAD = 1\n",
    "        GPU_CONFIG = \"A100-80GB\"\n",
    "    else:\n",
    "        BATCH_SIZE = 6\n",
    "        NUM_WORKERS = 6\n",
    "        ACCUMULATE_GRAD = 1\n",
    "        GPU_CONFIG = \"A100-40GB\"\nelif 'H100' in gpu_name:\n",
    "    BATCH_SIZE = 10\n",
    "    NUM_WORKERS = 10\n",
    "    ACCUMULATE_GRAD = 1\n",
    "    GPU_CONFIG = \"H100-80GB\"\nelse:\n",
    "    # Conservative defaults\n",
    "    if gpu_memory > 40:\n",
    "        BATCH_SIZE = 4\n",
    "        NUM_WORKERS = 4\n",
    "    elif gpu_memory > 20:\n",
    "        BATCH_SIZE = 2\n",
    "        NUM_WORKERS = 4\n",
    "    else:\n",
    "        BATCH_SIZE = 1\n",
    "        NUM_WORKERS = 2\n",
    "    ACCUMULATE_GRAD = 2\n",
    "    GPU_CONFIG = f\"{gpu_name} ({gpu_memory:.1f}GB)\"\n",
    "\nprint(f\"\\nüéØ Config: {GPU_CONFIG}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Workers: {NUM_WORKERS}\")\n",
    "print(f\"   Grad accumulation: {ACCUMULATE_GRAD}\")\n",
    "\n",
    "# Show nvidia-smi\ntry:\n",
    "    result = subprocess.run(\n",
    "        ['nvidia-smi', '--query-gpu=name,memory.total,memory.free,temperature.gpu',\n",
    "         '--format=csv,noheader'],\n",
    "        capture_output=True, text=True, timeout=5\n",
    "    )\n",
    "    print(f\"\\nüìä GPU Stats:\\n{result.stdout}\")\nexcept Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è  Could not query GPU: {e}\")\n",
    "\nprint(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Dataset Validation\n",
    "\n",
    "Validate your Finnish audio dataset before training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Expected dataset locations\n",
    "DATASET_OPTIONS = [\n",
    "    WORK_DIR / 'data' / 'FinnishSpeaker',\n",
    "    FISH_SPEECH_DIR / 'data' / 'FinnishSpeaker',\n",
    "    HOME / 'finnish-tts-training' / 'data' / 'FinnishSpeaker',\n",
    "]\n",
    "\n",
    "DATA_DIR = None\n",
    "for path in DATASET_OPTIONS:\n",
    "    if path.exists() and list(path.glob('*.wav')):\n",
    "        DATA_DIR = path\n",
    "        break\n",
    "\n",
    "if not DATA_DIR:\n",
    "    print(\"‚ö†Ô∏è  No dataset found!\")\n",
    "    print(f\"\\nExpected location: {WORK_DIR}/data/FinnishSpeaker/\")\n",
    "    print(\"\\nPlease:\")\n",
    "    print(\"1. Upload your dataset via SCP:\")\n",
    "    print(f\"   scp -r your_data/ user@instance:{WORK_DIR}/data/FinnishSpeaker/\")\n",
    "    print(\"2. Then re-run this cell\")\n",
    "    DATA_DIR = WORK_DIR / 'data' / 'FinnishSpeaker'\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\nelse:\n",
    "    print(f\"‚úÖ Dataset found at: {DATA_DIR}\")\n",
    "\nif DATA_DIR.exists() and list(DATA_DIR.glob('*.wav')):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"DATASET VALIDATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    wav_files = list(DATA_DIR.glob('*.wav'))\n",
    "    lab_files = list(DATA_DIR.glob('*.lab'))\n",
    "    npy_files = list(DATA_DIR.glob('*.npy'))\n",
    "    \n",
    "    print(f\"\\nüìä File counts:\")\n",
    "    print(f\"   WAV files: {len(wav_files)}\")\n",
    "    print(f\"   LAB files: {len(lab_files)}\")\n",
    "    print(f\"   NPY files: {len(npy_files)} (VQ tokens)\")\n",
    "    \n",
    "    # Check pairing\n",
    "    wav_stems = {f.stem for f in wav_files}\n",
    "    lab_stems = {f.stem for f in lab_files}\n",
    "    \n",
    "    missing_lab = wav_stems - lab_stems\n",
    "    missing_wav = lab_stems - wav_stems\n",
    "    \n",
    "    if missing_lab:\n",
    "        print(f\"\\n‚ö†Ô∏è  {len(missing_lab)} WAV files missing LAB\")\n",
    "    if missing_wav:\n",
    "        print(f\"\\n‚ö†Ô∏è  {len(missing_wav)} LAB files missing WAV\")\n",
    "    if not missing_lab and not missing_wav:\n",
    "        print(\"\\n‚úÖ All WAV-LAB pairs match!\")\n",
    "    \n",
    "    # Audio validation (sample)\n",
    "    if wav_files:\n",
    "        print(f\"\\nüîä Validating audio quality (sampling {min(10, len(wav_files))} files)...\")\n",
    "        sample_files = wav_files[:min(10, len(wav_files))]\n",
    "        \n",
    "        durations = []\n",
    "        sample_rates = []\n",
    "        channels_list = []\n",
    "        \n",
    "        for wav_file in tqdm(sample_files, desc=\"Checking\", leave=False):\n",
    "            try:\n",
    "                audio, sr = librosa.load(wav_file, sr=None)\n",
    "                durations.append(len(audio) / sr)\n",
    "                sample_rates.append(sr)\n",
    "                info = sf.info(wav_file)\n",
    "                channels_list.append(info.channels)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error: {wav_file.name}: {e}\")\n",
    "        \n",
    "        if durations:\n",
    "            print(f\"   Average duration: {np.mean(durations):.2f}s\")\n",
    "            print(f\"   Duration range: {np.min(durations):.2f}s - {np.max(durations):.2f}s\")\n",
    "            \n",
    "            sr_counts = Counter(sample_rates)\n",
    "            print(f\"   Sample rates: {dict(sr_counts)}\")\n",
    "            \n",
    "            if all(sr == 24000 for sr in sample_rates):\n",
    "                print(\"   ‚úÖ All samples at 24kHz (correct for Fish Speech)\")\n",
    "            else:\n",
    "                print(\"   ‚ö†Ô∏è  Mixed sample rates - should be 24kHz\")\n",
    "            \n",
    "            channel_counts = Counter(channels_list)\n",
    "            print(f\"   Channels: {dict(channel_counts)}\")\n",
    "            \n",
    "            if all(ch == 1 for ch in channels_list):\n",
    "                print(\"   ‚úÖ All samples are mono (correct)\")\n",
    "            else:\n",
    "                print(\"   ‚ö†Ô∏è  Some samples are stereo - should be mono\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Awaiting dataset at: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Download Base Model\n",
    "\n",
    "Ensure base model is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download, list_repo_files\n",
    "import os\n",
    "\n",
    "os.chdir(FISH_SPEECH_DIR)\n",
    "\n",
    "BASE_MODEL_PATH = FISH_SPEECH_DIR / 'checkpoints' / 'openaudio-s1-mini'\n",
    "BASE_MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BASE MODEL DOWNLOAD\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if (BASE_MODEL_PATH / 'model.pth').exists():\n",
    "    print(f\"\\n‚úÖ Base model already exists at: {BASE_MODEL_PATH}\")\n",
    "    print(\"\\nModel files:\")\n",
    "    for file in sorted(BASE_MODEL_PATH.glob('*')):\n",
    "        size = file.stat().st_size / 1024**2  # MB\n",
    "        print(f\"  {file.name:40s} {size:8.1f} MB\")\nelse:\n",
    "    print(f\"\\nüì• Downloading base model...\")\n",
    "    try:\n",
    "        snapshot_download(\n",
    "            repo_id=\"fishaudio/openaudio-s1-mini\",\n",
    "            local_dir=str(BASE_MODEL_PATH),\n",
    "            local_dir_use_symlinks=False\n",
    "        )\n",
    "        print(f\"‚úÖ Model downloaded to: {BASE_MODEL_PATH}\")\n",
    "        \n",
    "        print(\"\\nModel files:\")\n",
    "        for file in sorted(BASE_MODEL_PATH.glob('*')):\n",
    "            size = file.stat().st_size / 1024**2\n",
    "            print(f\"  {file.name:40s} {size:8.1f} MB\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Model download failed: {e}\")\n",
    "        print(f\"\\nTroubleshooting:\")\n",
    "        print(f\"1. Check HuggingFace authentication: huggingface-cli login\")\n",
    "        print(f\"2. Accept model license: https://huggingface.co/fishaudio/openaudio-s1-mini\")\n",
    "        print(f\"3. Try again\")\n",
    "        raise\n",
    "\nprint(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Training Configuration\n",
    "\n",
    "Configure training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "TRAINING_CONFIG = {\n",
    "    'project': 'FinnishSpeaker_2000_finetune',\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'num_workers': NUM_WORKERS,\n",
    "    'max_steps': 2000,  # Full training\n",
    "    'val_check_interval': 100,  # Validate every 100 steps\n",
    "    'accumulate_grad_batches': ACCUMULATE_GRAD,\n",
    "    'lora_r': 8,\n",
    "    'lora_alpha': 16,\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nProject: {TRAINING_CONFIG['project']}\")\n",
    "print(f\"Batch size: {TRAINING_CONFIG['batch_size']}\")\n",
    "print(f\"Workers: {TRAINING_CONFIG['num_workers']}\")\n",
    "print(f\"Max steps: {TRAINING_CONFIG['max_steps']}\")\n",
    "print(f\"LoRA: r={TRAINING_CONFIG['lora_r']}, alpha={TRAINING_CONFIG['lora_alpha']}\")\n",
    "\n",
    "# Estimate training time\nsteps_per_hour = (3600 / (15 * 60)) * TRAINING_CONFIG['val_check_interval']  # ~15 min per 100 steps\ntotal_hours = TRAINING_CONFIG['max_steps'] / steps_per_hour\nestimated_cost = total_hours * 1.44  # $1.44/hr for L40S (adjust if needed)\n\nprint(f\"\\n‚è±Ô∏è  Estimated time: {total_hours:.1f} hours\")\nprint(f\"üí∞ Estimated cost: ${estimated_cost:.2f} (L40S @ $1.44/hr)\")\nprint(f\"\\nNote: Actual times vary by GPU and dataset complexity\")\nprint(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Start Training\n",
    "\n",
    "Launch the training process. This will take 1-4 hours depending on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "os.chdir(FISH_SPEECH_DIR)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ STARTING TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTimestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"GPU: {gpu_name}\")\n",
    "print(f\"Dataset: {DATA_DIR}\")\n",
    "print(f\"\\nThis will take approximately {total_hours:.1f} hours...\\n\")\n",
    "\n",
    "# Build training command\ncmd = [\n",
    "    'python', 'fish_speech/train.py',\n",
    "    '--config-name', 'text2semantic_finetune',\n",
    "    f'project={TRAINING_CONFIG[\"project\"]}',\n",
    "    f'train_dataset.proto_files={FISH_SPEECH_DIR}/data/protos',\n",
    "    f'trainer.max_steps={TRAINING_CONFIG[\"max_steps\"]}',\n",
    "    f'trainer.val_check_interval={TRAINING_CONFIG[\"val_check_interval\"]}',\n",
    "    f'model.lora_config.r={TRAINING_CONFIG[\"lora_r\"]}',\n",
    "    f'model.lora_config.lora_alpha={TRAINING_CONFIG[\"lora_alpha\"]}',\n",
    "    f'data.batch_size={TRAINING_CONFIG[\"batch_size\"]}',\n",
    "    f'data.num_workers={TRAINING_CONFIG[\"num_workers\"]}',\n",
    "    f'trainer.accumulate_grad_batches={TRAINING_CONFIG[\"accumulate_grad_batches\"]}',\n",
    "    'pretrained_ckpt_path=checkpoints/openaudio-s1-mini/model.pth',\n",
    "]\n",
    "\nprint(\"Command:\")\nprint(' '.join(cmd))\nprint(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\ntry:\n",
    "    process = subprocess.Popen(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        text=True,\n",
    "        bufsize=1\n",
    "    )\n",
    "    \n",
    "    # Stream output\n",
    "    for line in process.stdout:\n",
    "        print(line, end='')\n",
    "    \n",
    "    return_code = process.wait()\n",
    "    \n",
    "    if return_code == 0:\n",
    "        print(f\"\\n‚úÖ Training completed successfully!\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå Training failed with return code {return_code}\")\n",
    "        \nexcept KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è  Training interrupted by user\")\n",
    "    process.terminate()\nexcept Exception as e:\n",
    "    print(f\"\\n‚ùå Error: {e}\")\n",
    "    raise\n",
    "\nprint(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Monitor Training (Optional)\n",
    "\n",
    "Check training progress in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor checkpoints\nproject_dir = FISH_SPEECH_DIR / 'results' / TRAINING_CONFIG['project']\nif project_dir.exists():\n",
    "    print(f\"Project directory: {project_dir}\")\n",
    "    \n",
    "    ckpt_dir = project_dir / 'checkpoints'\n",
    "    if ckpt_dir.exists():\n",
    "        ckpts = sorted(ckpt_dir.glob('step_*.ckpt'))\n",
    "        print(f\"\\nüì¶ Checkpoints ({len(ckpts)}):\")\n",
    "        for ckpt in ckpts[-5:]:\n",
    "            size = ckpt.stat().st_size / 1024**2\n",
    "            print(f\"  {ckpt.name:40s} {size:8.1f} MB\")\n",
    "    \n",
    "    # Show training log\n",
    "    log_file = project_dir / 'train.log'\n",
    "    if log_file.exists():\n",
    "        print(f\"\\nüìù Recent logs:\")\n",
    "        with open(log_file) as f:\n",
    "            lines = f.readlines()[-10:]\n",
    "            for line in lines:\n",
    "                print(line.strip())\nelse:\n",
    "    print(f\"‚ö†Ô∏è  Project directory not found: {project_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Export Model\n",
    "\n",
    "Prepare trained model for download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL EXPORT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "project_dir = FISH_SPEECH_DIR / 'results' / TRAINING_CONFIG['project']\nif not project_dir.exists():\n",
    "    print(f\"\\n‚ö†Ô∏è  Project not found: {project_dir}\")\n",
    "    print(\"Please run training first.\")\nelse:\n",
    "    # Find latest checkpoint\n",
    "    ckpt_dir = project_dir / 'checkpoints'\n",
    "    if ckpt_dir.exists():\n",
    "        ckpts = sorted(ckpt_dir.glob('step_*.ckpt'))\n",
    "        if ckpts:\n",
    "            latest_ckpt = ckpts[-1]\n",
    "            print(f\"\\nüì¶ Latest checkpoint: {latest_ckpt.name}\")\n",
    "            \n",
    "            # Create export directory\n",
    "            export_dir = WORK_DIR / 'exports'\n",
    "            export_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            # Archive results\n",
    "            archive_name = f\"finnish-tts-{datetime.now().strftime('%Y%m%d-%H%M%S')}.tar.gz\"\n",
    "            archive_path = export_dir / archive_name\n",
    "            \n",
    "            print(f\"\\nüì• Creating archive: {archive_name}\")\n",
    "            with tarfile.open(archive_path, 'w:gz') as tar:\n",
    "                # Add checkpoints\n",
    "                tar.add(ckpt_dir, arcname='checkpoints')\n",
    "                # Add logs\n",
    "                log_file = project_dir / 'train.log'\n",
    "                if log_file.exists():\n",
    "                    tar.add(log_file, arcname='train.log')\n",
    "            \n",
    "            size_gb = archive_path.stat().st_size / 1024**3\n",
    "            print(f\"‚úÖ Archive created: {archive_path}\")\n",
    "            print(f\"   Size: {size_gb:.2f} GB\")\n",
    "            print(f\"\\nüì• Download command:\")\n",
    "            print(f\"   scp user@instance:{archive_path} .\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  No checkpoints found\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Checkpoint directory not found: {ckpt_dir}\")\n",
    "\nprint(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Summary\n",
    "\n",
    "Training workflow complete!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"‚úÖ TRAINING WORKFLOW COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTimestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"GPU: {gpu_name}\")\n",
    "print(f\"Training steps: {TRAINING_CONFIG['max_steps']}\")\n",
    "print(f\"LoRA config: r={TRAINING_CONFIG['lora_r']}, alpha={TRAINING_CONFIG['lora_alpha']}\")\n",
    "\nprint(\"\\nüìã Next Steps:\")\nprint(\"\\n1. Download your model:\")\nprint(f\"   cd {export_dir}\")\nprint(f\"   scp user@instance:exports/*.tar.gz .\")\n\nprint(\"\\n2. Extract on your machine:\")\nprint(\"   tar -xzf finnish-tts-*.tar.gz\")\n\nprint(\"\\n3. Test inference:\")\nprint(\"   python fish_speech/tools/llama/generate.py \\\\\")\nprint(\"     --checkpoint checkpoints/step_000002000.ckpt \\\\\")\nprint(\"     --text 'Hyv√§√§ huomenta!' \\\\\")\nprint(\"     --output output.wav\")\n\nprint(\"\\nüéØ Deployment:\")\nprint(\"   - Merge LoRA weights into base model\")\nprint(\"   - Deploy to production inference server\")\nprint(\"   - Integrate with WebUI or API\")\n\nprint(\"\\nüìö Documentation:\")\nprint(\"   - Deployment: https://github.com/akusingh/nvidia-brev-launchables\")\nprint(\"   - Fish Speech: https://github.com/fishaudio/fish-speech\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"Happy Training! üá´üáÆüöÄ\")\nprint(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
