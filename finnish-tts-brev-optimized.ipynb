{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finnish TTS Model Training on Kaggle\n",
    "\n",
    "**Project:** Train Finnish TTS model using Fish Speech + LoRA  \n",
    "**Dataset:** 2000 Finnish samples (cv-15 + parliament)  \n",
    "**Expected Time:** ~5-6 hours on P100 GPU  \n",
    "**Cost:** FREE (Kaggle free tier - 30 hours/week)\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. **Kaggle Account:** Create account at https://kaggle.com\n",
    "2. **GPU Enabled:** Settings → Enable GPU Accelerator (P100 or T4)\n",
    "3. **Dataset Upload:** Upload `FinnishSpeaker_2000_partial.tar.gz` (636 MB) as Kaggle Dataset\n",
    "4. **HuggingFace Token:** For downloading base model\n",
    "5. **Session Limit:** 12 hours max per session (enough for training)\n",
    "\n",
    "---\n",
    "\n",
    "## What This Notebook Does\n",
    "\n",
    "1. ✅ Install Fish Speech\n",
    "2. ✅ Download base model (5GB)\n",
    "3. ✅ Load your dataset (2000 samples, 502 VQ tokens already extracted)\n",
    "4. ✅ Extract remaining 1498 VQ tokens (~30-40 min)\n",
    "5. ✅ Pack dataset to protos\n",
    "6. ✅ Train with LoRA (2000 steps, ~4-5 hours)\n",
    "7. ✅ Merge LoRA weights\n",
    "8. ✅ Download trained model\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU is available\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system dependencies\n",
    "!apt-get update -qq\n",
    "!apt-get install -y -qq sox libsox-dev ffmpeg\n",
    "\n",
    "# Clone Fish Speech repository\n",
    "!git clone https://github.com/fishaudio/fish-speech.git\n",
    "%cd fish-speech\n",
    "\n",
    "# Install Python dependencies explicitly\n",
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q hydra-core omegaconf pyrootutils\n",
    "!pip install -q lightning tensorboard\n",
    "!pip install -q transformers tokenizers\n",
    "!pip install -q loralib\n",
    "!pip install -q nemo_text_processing WeTextProcessing\n",
    "!pip install -q gradio protobuf fish-audio-preprocess soundfile\n",
    "\n",
    "# Install Fish Speech itself\n",
    "!pip install -q -e .\n",
    "\n",
    "print(\"\\n✅ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Login to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Enter your HuggingFace token\n",
    "login()\n",
    "\n",
    "print('\\n⚠️ IMPORTANT: You must request access to the gated model:')\n",
    "print('Visit: https://huggingface.co/fishaudio/openaudio-s1-mini')\n",
    "print('Click \"Request Access\" button (approval is usually instant)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Download Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pre-trained model (~5 GB, takes 2-3 minutes)\n",
    "!hf download fishaudio/openaudio-s1-mini --local-dir checkpoints/openaudio-s1-mini\n",
    "\n",
    "# Verify download\n",
    "!ls -lh checkpoints/openaudio-s1-mini/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Load Dataset from Kaggle Input\n",
    "\n",
    "**Before running:** Add your dataset as input in Kaggle notebook settings:\n",
    "1. Click \"+ Add Data\" → \"Your Datasets\"\n",
    "2. Select your uploaded `FinnishSpeaker_2000_partial` dataset\n",
    "3. It will mount at `/kaggle/input/finnishspeaker-2000-partial/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dataset from Kaggle input\n",
    "!mkdir -p data\n",
    "!tar -xzf /kaggle/input/finnishspeaker-2000-partial/FinnishSpeaker_2000_partial.tar.gz -C data/\n",
    "\n",
    "# Verify extraction\n",
    "!echo \"WAV files: $(ls data/FinnishSpeaker/*.wav | wc -l)\"\n",
    "!echo \"LAB files: $(ls data/FinnishSpeaker/*.lab | wc -l)\"\n",
    "!echo \"NPY files (VQ tokens): $(ls data/FinnishSpeaker/*.npy | wc -l)\"\n",
    "!echo \"\"\n",
    "!echo \"Sample files:\"\n",
    "!ls data/FinnishSpeaker/ | head -10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Extract Remaining VQ Tokens\n",
    "\n",
    "You have 502/2000 VQ tokens. This step extracts the remaining 1498 tokens.  \n",
    "**Time:** ~30-40 minutes on P100, ~60 minutes on T4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract VQ tokens for files that don't have them yet\n",
    "!python tools/vqgan/extract_vq.py \\\n",
    "  data/FinnishSpeaker \\\n",
    "  --num-workers 4 \\\n",
    "  --batch-size 32 \\\n",
    "  --config-name modded_dac_vq \\\n",
    "  --checkpoint-path checkpoints/openaudio-s1-mini/codec.pth\n",
    "\n",
    "# Verify all tokens extracted\n",
    "!echo \"\\nFinal VQ token count: $(ls data/FinnishSpeaker/*.npy | wc -l)\"\n",
    "!echo \"Expected: 2000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Pack Dataset into Protos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pack dataset into protocol buffer format\n",
    "!python tools/llama/build_dataset.py \\\n",
    "  --input \"data/FinnishSpeaker\" \\\n",
    "  --output \"data/protos\" \\\n",
    "  --text-extension .lab \\\n",
    "  --num-workers 4\n",
    "\n",
    "# Verify protos created\n",
    "!ls -lh data/protos/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Start Training\n",
    "\n",
    "**Configuration:**\n",
    "- Samples: 2000\n",
    "- Steps: 2000\n",
    "- Batch size: 2 (with gradient accumulation)\n",
    "- Checkpoints: Every 250 steps\n",
    "- Time: ~4-5 hours on P100\n",
    "\n",
    "Training will auto-save checkpoints. If session disconnects, you can resume from last checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with LoRA fine-tuning\n",
    "!python fish_speech/train.py \\\n",
    "  --config-name text2semantic_finetune \\\n",
    "  project=FinnishSpeaker_2000_finetune \\\n",
    "  +lora@model.model.lora_config=r_8_alpha_16 \\\n",
    "  data.batch_size=2 \\\n",
    "  data.num_workers=4 \\\n",
    "  trainer.max_steps=2000 \\\n",
    "  trainer.val_check_interval=250 \\\n",
    "  trainer.accumulate_grad_batches=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Monitor Training (Optional)\n",
    "\n",
    "Run this in a separate cell while training to monitor progress:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training progress\n",
    "!ls -lht results/FinnishSpeaker_2000_finetune/checkpoints/ | head -5\n",
    "\n",
    "# View tensorboard logs (optional)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir results/FinnishSpeaker_2000_finetune/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Merge LoRA Weights\n",
    "\n",
    "After training completes, merge the LoRA adapter with the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the final checkpoint (or best checkpoint)\n",
    "!ls -lh results/FinnishSpeaker_2000_finetune/checkpoints/\n",
    "\n",
    "# Merge LoRA weights (update step number if needed)\n",
    "!python tools/llama/merge_lora.py \\\n",
    "  --lora-config r_8_alpha_16 \\\n",
    "  --base-weight checkpoints/openaudio-s1-mini \\\n",
    "  --lora-weight results/FinnishSpeaker_2000_finetune/checkpoints/step_000002000.ckpt \\\n",
    "  --output checkpoints/FinnishSpeaker_2000_finetuned\n",
    "\n",
    "# Verify merged model\n",
    "!ls -lh checkpoints/FinnishSpeaker_2000_finetuned/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Download Trained Model\n",
    "\n",
    "**Choose one method to download your trained model:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method A: Download Directly (Kaggle Notebook Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create archive for download\n",
    "!tar -czf FinnishSpeaker_2000_trained.tar.gz checkpoints/FinnishSpeaker_2000_finetuned/\n",
    "\n",
    "# The file will appear in Kaggle Output section (right sidebar)\n",
    "!ls -lh FinnishSpeaker_2000_trained.tar.gz\n",
    "print(\"\\n✅ Model packaged! Find it in Output tab →\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method B: Upload to HuggingFace Hub (Recommended for Sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "# Create a new model repo (will be private by default)\n",
    "repo_id = \"YOUR_USERNAME/finnish-tts-finetuned\"  # Change this!\n",
    "\n",
    "# Upload model files\n",
    "api.upload_folder(\n",
    "    folder_path=\"checkpoints/FinnishSpeaker_2000_finetuned\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=\"model\",\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Model uploaded to: https://huggingface.co/{repo_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method C: Save LoRA Adapter Only (8 MB vs 3.2 GB)\n",
    "\n",
    "More efficient - just save the LoRA weights, use with base model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package just the LoRA checkpoint\n",
    "!mkdir -p lora_adapter\n",
    "!cp results/FinnishSpeaker_2000_finetune/checkpoints/step_000002000.ckpt lora_adapter/\n",
    "!tar -czf FinnishSpeaker_2000_lora.tar.gz lora_adapter/\n",
    "\n",
    "!ls -lh FinnishSpeaker_2000_lora.tar.gz\n",
    "print(\"\\n✅ LoRA adapter packaged (only 8 MB!)\")\n",
    "print(\"Use with base model: fishaudio/openaudio-s1-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Quick Test (Optional)\n",
    "\n",
    "Test the model with a short Finnish sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick inference test\n",
    "test_text = \"Hei, kuinka voit?\"\n",
    "\n",
    "# Generate audio (basic CLI inference)\n",
    "!python tools/llama/generate.py \\\n",
    "  --text \"$test_text\" \\\n",
    "  --checkpoint-path checkpoints/FinnishSpeaker_2000_finetuned \\\n",
    "  --output test_output.wav\n",
    "\n",
    "# Play audio\n",
    "from IPython.display import Audio\n",
    "Audio('test_output.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Training Summary\n",
    "\n",
    "**What you trained:**\n",
    "- Base model: fishaudio/openaudio-s1-mini\n",
    "- Dataset: 2000 Finnish samples (cv-15 + parliament)\n",
    "- Method: LoRA fine-tuning (r=8, alpha=16)\n",
    "- Steps: 2000\n",
    "- Time: ~5-6 hours\n",
    "\n",
    "**Output files:**\n",
    "- Full model: `checkpoints/FinnishSpeaker_2000_finetuned/` (3.2 GB)\n",
    "- LoRA only: `lora_adapter/step_000002000.ckpt` (8 MB)\n",
    "- Checkpoints: `results/FinnishSpeaker_2000_finetune/checkpoints/` (for resuming)\n",
    "\n",
    "**Next steps:**\n",
    "1. Download model to your Mac\n",
    "2. Test with Fish Speech WebUI\n",
    "3. Add more data and train again (incremental learning)\n",
    "4. Share with team via HuggingFace\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "**Out of Memory:**\n",
    "- Reduce `data.batch_size` to 1\n",
    "- Increase `trainer.accumulate_grad_batches` to 4\n",
    "\n",
    "**Session Timeout:**\n",
    "- Training auto-saves checkpoints every 250 steps\n",
    "- Restart notebook and change training command to resume:\n",
    "  ```python\n",
    "  !python fish_speech/train.py \\\n",
    "    --config-name text2semantic_finetune \\\n",
    "    project=FinnishSpeaker_2000_finetune \\\n",
    "    +lora@model.model.lora_config=r_8_alpha_16 \\\n",
    "    ckpt_path=results/FinnishSpeaker_2000_finetune/checkpoints/last.ckpt\n",
    "  ```\n",
    "\n",
    "**HuggingFace Access Denied:**\n",
    "- Make sure you requested access at https://huggingface.co/fishaudio/openaudio-s1-mini\n",
    "- Wait a few minutes for approval\n",
    "- Re-run Step 3 with correct token\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
