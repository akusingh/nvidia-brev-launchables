# Should Full Fine-tuning Workflow Be in Launchable?
**Date:** December 2, 2025  
**Question:** Should the 4000-sample full fine-tuning ‚Üí single-speaker LoRA workflow be part of the NVIDIA Launchable?

---

## üéØ What is the Launchable For?

### Current Launchable Scope (from launchable.yaml):
```yaml
name: Finnish TTS Fine-Tuning
description: >
  Fine-tune Fish Speech TTS model on Finnish language dataset.
  Produces high-quality Finnish text-to-speech with custom voice characteristics.

target_audience:
  - Researchers adapting TTS to new languages
  - Developers building Finnish voice applications
  - ML engineers learning LoRA fine-tuning
```

### Current Workflow:
```
1. User uploads Finnish dataset (or uses included sample)
2. setup.sh installs dependencies + downloads base model
3. VQ extraction (cached from previous run)
4. LoRA fine-tuning on all data (2000-4000 samples)
5. Merge LoRA weights
6. Test inference
7. Download results
```

**Current focus:** Single-purpose LoRA training

---

## üîÄ Two-Phase Workflow vs Single LoRA

### Option A: Keep Current Scope (LoRA Only)
```
What it does:
- LoRA fine-tuning on all Finnish data
- Assumes base model is "close enough" to Finnish
- 2800 steps, 4 hours, $5.28
- Produces one speaker-generic Finnish model

User gets:
‚úÖ Working Finnish TTS model
‚úÖ Fast training (4 hours)
‚úÖ Simple workflow (one command)
‚úÖ Good quality (~85-90%)

Limitations:
‚ö†Ô∏è Not optimized for single speaker
‚ö†Ô∏è Blends all speaker characteristics
‚ö†Ô∏è May not fully capture Finnish phonology
```

### Option B: Add Two-Phase Workflow (Full + LoRA)
```
What it does:
Phase 1: Full fine-tune all 4000 samples (3 epochs)
  ‚Üí Adapts base model to Finnish language
Phase 2: Select best speaker
Phase 3: LoRA fine-tune on single speaker
  ‚Üí Adds speaker-specific characteristics
Phase 4: Inference testing

Timeline: 6.6 hours
Cost: $5.30-$7.94
Quality: 95-98%

User gets:
‚úÖ Language-adapted base model
‚úÖ Speaker-specific LoRA model
‚úÖ Higher quality output
‚úÖ More flexibility (can train new speakers)

Limitations:
‚ö†Ô∏è 2√ó longer (6.6 hrs vs 3-4 hrs)
‚ö†Ô∏è More complex workflow
‚ö†Ô∏è Higher cost ($7.94 vs $5.28)
‚ö†Ô∏è Requires speaker selection logic
```

---

## üìä Comparison Matrix

| Factor | Current LoRA-Only | Two-Phase (Full + LoRA) |
|--------|-------------------|--------------------------|
| **Training Time** | 3-4 hours | 6.6 hours |
| **Cost** | $5.28 | $5.30-$7.94 |
| **Complexity** | Simple (1 script) | Complex (3 phases) |
| **Quality** | 85-90% | 95-98% |
| **Use Case** | Generic Finnish TTS | Specific speaker voice |
| **Finnish Adaptation** | Partial (LoRA only) | Full (all params) |
| **Flexibility** | Train once | Reuse base, train new speakers |
| **Launchable Size** | Small (~500 lines) | Large (~1500 lines) |
| **User Complexity** | Low (1 click) | Medium (select speaker) |
| **Output Size** | 47MB (LoRA only) | 3.5GB (full) + 47MB (LoRA) |

---

## üéì Educational Value

### Current Launchable Teaches:
1. LoRA fine-tuning basics
2. TTS model adaptation
3. Dataset preparation (VQ extraction)
4. Checkpoint merging

### Two-Phase Would Teach:
1. ‚úÖ All of the above, PLUS:
2. Full fine-tuning vs LoRA trade-offs
3. Multi-stage training pipelines
4. Speaker selection strategies
5. Language adaptation workflows
6. Model architecture freezing/unfreezing

**Educational Winner:** Two-phase workflow (more comprehensive)

---

## üí∞ Cost-Benefit Analysis

### For Users:

**Current LoRA-Only:**
```
Investment: $5.28
Output: Working Finnish TTS model
ROI: High (simple, fast, works)
Best for: Quick experiments, testing Fish Speech
```

**Two-Phase:**
```
Investment: $7.94
Output: Production-quality speaker model + reusable base
ROI: Very High (better quality, more flexibility)
Best for: Production use, multi-speaker datasets
```

**Verdict:** Two-phase has better ROI IF user has:
- Multiple speakers in dataset
- Production quality requirements  
- Plans to train more speakers later

---

## üéØ Recommendation: HYBRID APPROACH

### Make it Optional!

```yaml
# In launchable.yaml
training_mode:
  type: choice
  options:
    - quick_lora      # Current workflow (default)
    - full_finetune   # Two-phase workflow
  default: quick_lora
  description: |
    quick_lora: Fast LoRA training on all data (4 hrs, $5)
    full_finetune: Full model adaptation + speaker LoRA (6.6 hrs, $8)
```

### Workflow Logic:

```python
if training_mode == "quick_lora":
    # Current workflow
    train_lora(all_samples, steps=3000)
    merge_and_export()
    
elif training_mode == "full_finetune":
    # Two-phase workflow
    full_finetune(all_samples, epochs=3)
    best_speaker = select_speaker_by_count()
    train_lora(best_speaker_samples, until_convergence=True)
    merge_and_export()
```

### User Experience:

```bash
# Quick mode (default)
brev open --name finnish-tts-training
# Notebook starts with training_mode = "quick_lora"
# 4 hours later: One Finnish TTS model ready

# Advanced mode
brev open --name finnish-tts-training
# User edits: training_mode = "full_finetune"
# 6.6 hours later: Language-adapted base + speaker LoRA ready
```

---

## ‚úÖ Implementation Plan

### Phase 1: Keep Current Scope (Launchable V1)
**Goal:** Get accepted into NVIDIA Launchables  
**Timeline:** Now - December 15, 2025

```
Scope:
- LoRA fine-tuning only
- Simple workflow (setup ‚Üí VQ ‚Üí train ‚Üí merge)
- 2000 sample demo dataset
- 4 hours, $5.28
- Clear documentation

Why:
‚úÖ Simpler to review
‚úÖ Faster approval
‚úÖ Lower barrier to entry
‚úÖ Proven to work
```

### Phase 2: Add Two-Phase Option (Launchable V2)
**Goal:** Advanced users can do full fine-tuning  
**Timeline:** January 2026 (after V1 acceptance)

```
Scope:
- Add `training_mode` parameter
- Implement full fine-tuning path
- Add speaker selection logic
- Update documentation
- Show cost comparison

Why:
‚úÖ V1 already approved (less risk)
‚úÖ Can gather user feedback first
‚úÖ More time to test complex workflow
‚úÖ Doesn't delay V1 launch
```

---

## üéØ Final Answer

### For NVIDIA Launchables Submission:

**‚úÖ START WITH LORA-ONLY (Current Scope)**

**Reasons:**
1. **Simplicity:** One-click workflow, easier to explain
2. **Speed:** 4 hours vs 6.6 hours (better demo experience)
3. **Cost:** $5.28 vs $7.94 (lower barrier)
4. **Proven:** We already completed this workflow successfully
5. **Acceptance:** Simpler submissions approved faster

**üîÑ ADD FULL FINE-TUNING LATER (V2)**

**Reasons:**
1. **User Feedback:** See what users actually need
2. **Testing:** More time to validate complex workflow
3. **Documentation:** Can write better guides after V1 launch
4. **Risk:** Don't delay V1 acceptance with scope creep

---

## üìã Scope Definition

### Launchable V1 (Submit Now):

```yaml
name: Finnish TTS Fine-Tuning with LoRA
tagline: Train Fish Speech TTS on Finnish in 4 hours ($5)

workflow:
  1. Upload Finnish dataset (or use 2000-sample demo)
  2. Auto-extract VQ tokens (cached)
  3. LoRA fine-tune on all data (2800 steps)
  4. Merge weights
  5. Test inference
  6. Download model

time: ~4 hours
cost: $5.28 (A100-80GB)
output: 47MB LoRA checkpoint
quality: 85-90% (good for most use cases)
difficulty: Beginner-friendly

innovation:
  - VQ token caching (saves $0.30/run)
  - Auto-download dataset from HuggingFace
  - Reproducible config (launchable.yaml)
```

### Launchable V2 (Future):

```yaml
name: Finnish TTS Fine-Tuning (LoRA + Full)
tagline: Train Fish Speech TTS on Finnish with optional full fine-tuning

workflow:
  MODE 1: Quick LoRA (default)
    - Same as V1
    
  MODE 2: Full Fine-Tuning
    1. Full fine-tune on all 4000 samples (3 epochs)
    2. Auto-select speaker with most samples
    3. LoRA fine-tune on best speaker
    4. Test inference
    5. Download base + LoRA

time: 
  - Quick: ~4 hours ($5.28)
  - Full: ~6.6 hours ($7.94)
  
output:
  - Quick: 47MB LoRA
  - Full: 3.5GB base + 47MB LoRA
  
quality:
  - Quick: 85-90%
  - Full: 95-98%
  
difficulty:
  - Quick: Beginner
  - Full: Intermediate
```

---

## üöÄ Action Items

### For Launchable V1 Submission (This Week):

- [x] Keep current LoRA-only workflow
- [ ] Clean up setup.sh
- [ ] Add dataset download from HuggingFace
- [ ] Write clear README with cost/time estimates
- [ ] Test on fresh instance (smoke test)
- [ ] Submit to brev-support@nvidia.com

### For Launchable V2 (Future):

- [ ] Implement training_mode parameter
- [ ] Add full fine-tuning script
- [ ] Build speaker selection logic
- [ ] Create comparison documentation
- [ ] Test both modes end-to-end
- [ ] Update README with mode comparison

---

## üí° Key Insight

**Don't let perfect be the enemy of good.**

The current LoRA-only workflow:
- ‚úÖ Works reliably
- ‚úÖ Teaches key concepts
- ‚úÖ Produces usable results
- ‚úÖ Is cost-effective
- ‚úÖ Is simple to explain

The full fine-tuning workflow:
- ‚úÖ Better quality
- ‚ö†Ô∏è More complex
- ‚ö†Ô∏è Longer time
- ‚ö†Ô∏è Higher cost
- ‚ö†Ô∏è Harder to debug

**Ship V1, iterate to V2.** üöÄ

---

## Summary Table

| Aspect | V1: LoRA-Only | V2: Full + LoRA |
|--------|---------------|-----------------|
| **Scope** | Current workflow | Add full fine-tune option |
| **Timeline** | Submit this week | January 2026 |
| **Complexity** | Simple (1 mode) | Complex (2 modes) |
| **Time** | 4 hours | 4 or 6.6 hours |
| **Cost** | $5.28 | $5.28 or $7.94 |
| **Quality** | 85-90% | 85-90% or 95-98% |
| **Risk** | Low (proven) | Medium (untested) |
| **Acceptance Odds** | High ‚úÖ | Unknown |

**Decision: Submit V1 now, build V2 after acceptance.** ‚úÖ

