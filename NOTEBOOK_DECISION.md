# ğŸ““ Using A100 Notebook for Launchables

## âœ… **YES, Use the A100 Notebook!**

**Why it's perfect:**
- âœ… **Proven to work** - Successfully trained on A100
- âœ… **Complete workflow** - Setup â†’ Training â†’ Export
- âœ… **Well documented** - 12 markdown cells with explanations
- âœ… **Real commands** - Actual working code, not theoretical

**File:** `~/Downloads/finnish-tts-training-COMPLETED.ipynb`
- 43 cells total
- 31 code cells (actual commands)
- 12 markdown cells (explanations)

---

## ğŸ”§ **What Needs to Be Cleaned Up**

### 1. **Remove Hardcoded Paths**

**Find and replace:**
```python
# BEFORE (A100-specific):
/home/shadeform/finnish-tts-brev/
/home/shadeform/data/

# AFTER (generic):
${HOME}/nvidia-brev-launchables/
${HOME}/data/
```

### 2. **Remove Instance-Specific Cells**

**Remove these:**
- Duplicate cells (e.g., two `nvidia-smi` cells)
- Cells specific to Brev instance (pip install in venv)
- Debug cells you added during troubleshooting
- Cells with hardcoded speaker IDs

### 3. **Add User Instructions**

**Add at the top:**
```markdown
## ğŸš€ Welcome to Finnish TTS Training!

This notebook will guide you through training a Finnish TTS model.

**Before starting:**
1. âœ… Setup script has run (automatic)
2. ğŸ“ Upload your Finnish audio data to `datasets/finnish-tts-raw/`
3. ğŸ’° Training takes ~4 hours (~$5 on A100)

**What you need:**
- Finnish audio files (.wav, 44.1kHz)
- Text transcripts (.lab files)
- Minimum 500 samples (1 hour audio)
```

### 4. **Update Training Command**

**Current (in notebook):**
```python
!python fish_speech/train.py \
  --config-name text2semantic_finetune \
  pretrained_ckpt_path=/home/shadeform/finnish-tts-brev/checkpoints/openaudio-s1-mini \
  train_dataset.proto_files=[/home/shadeform/finnish-tts-brev/data/protos] \
  ...
```

**Fixed:**
```python
!python fish_speech/train.py \
  --config-name text2semantic_finetune \
  pretrained_ckpt_path=${HOME}/nvidia-brev-launchables/checkpoints/openaudio-s1-mini \
  train_dataset.proto_files=[${HOME}/data/protos] \
  ...
```

### 5. **Add Cost Estimates**

**Add markdown cell:**
```markdown
## ğŸ’° Cost Estimate

This cell will run for ~4 hours.

| GPU | Cost/hr | Total Cost |
|-----|---------|------------|
| A100-80GB | $1.20 | ~$4.80 |
| L40S | $0.60 | ~$2.40 |

**Progress:** You can monitor training in real-time below.
Press Ctrl+C to stop (checkpoints are saved every 100 steps).
```

---

## ğŸ¯ **Quick Clean-Up Plan**

### Option A: Manual Clean (15 min)

1. Copy notebook to repo:
   ```bash
   cp ~/Downloads/finnish-tts-training-COMPLETED.ipynb \
      /Users/arunkumar.singh/nvidia-brev/finnish-tts-training.ipynb
   ```

2. Open in VS Code

3. Find/Replace:
   - `/home/shadeform/finnish-tts-brev` â†’ `${HOME}/nvidia-brev-launchables`
   - `/home/shadeform/data` â†’ `${HOME}/data`

4. Remove duplicate cells

5. Add user instructions at top

6. Save and commit

### Option B: I Clean It For You (5 min)

I can:
1. âœ… Create a cleaned version
2. âœ… Remove hardcoded paths
3. âœ… Add user instructions
4. âœ… Add cost estimates
5. âœ… Remove debug cells
6. âœ… Make it Launchable-ready

---

## ğŸ“‹ **Recommended Structure for Launchables**

```
Cell 1: Welcome + Prerequisites
Cell 2: Environment Check (GPU, Python, Fish Speech)
Cell 3: Data Upload Instructions
Cell 4: Convert Dataset (WAV â†’ VQ tokens)
Cell 5: Pack Dataset (create protos)
Cell 6: Training Configuration (show parameters)
Cell 7: Start Training (the big one, ~4 hours)
Cell 8: Monitor Progress (loss curves)
Cell 9: Export Model (merge LoRA)
Cell 10: Test Inference (generate sample)
Cell 11: Download Results
```

---

## ğŸš€ **What Should We Do?**

**Option 1: I clean the notebook for you** (Recommended, fast)
- Takes 5 minutes
- I remove all hardcoded paths
- Add user instructions
- Ready to push to GitHub

**Option 2: You clean it manually**
- Takes 15 minutes
- You have full control
- I can guide you

**Option 3: Create new simplified notebook**
- Takes 30 minutes
- Start fresh, cleaner
- But loses your proven workflow

---

## ğŸ’¡ **My Strong Recommendation**

**Use Option 1: Let me clean the A100 notebook**

**Why?**
- âœ… It **already works** (proven on A100)
- âœ… Has the **exact commands** that succeeded
- âœ… Includes all the **fixes** you discovered (protobuf, workers, etc.)
- âœ… Just needs **path updates** (5 min work)
- âœ… You can verify it still makes sense

**Then:**
1. I clean it â†’ 5 min
2. You review â†’ 2 min
3. Push to GitHub â†’ 1 min
4. Create Launchable â†’ 5 min
5. **Total: 13 minutes to submission!** ğŸš€

---

## ğŸ¤” **What Do You Want?**

**A)** Let me clean the A100 notebook for you (fast)  
**B)** You'll clean it manually (you control)  
**C)** Create new simplified notebook (fresh start)

**I recommend A!** Want me to do it? ğŸš€
